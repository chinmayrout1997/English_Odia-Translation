{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type S\n",
      "[('PRP', 'They'), ('VBN', 'eaten'), ('VBP', 'have')]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Nov 18 00:07:23 2017\n",
    "\n",
    "@author: ayesha\n",
    "\"\"\"\n",
    "\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "import re\n",
    "import ast\n",
    "from nltk.tree import Tree\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "\n",
    "def reorder(sentence):\n",
    "    tag_sen = nlp.annotate(sentence, properties={           #first import the parse tree\n",
    "  'annotators': 'tokenize,ssplit,pos,depparse,parse',\n",
    "  'outputFormat': 'json'\n",
    "  })\n",
    "    tag_sen = str(tag_sen['sentences'][0]['parse'])\n",
    "    sen_type = Tree.fromstring(tag_sen)[0].label()          #identify the type of sentence\n",
    "    print 'type', sen_type\n",
    "    \n",
    "    tag_sen = re.sub('[ \\t\\n]+', ' ', tag_sen)              #remove any new line and redundant whitespace character\n",
    "    \n",
    "    file_name = {'S' : 'declarative.txt', 'SBARQ' : 'interrogative.txt'}\n",
    "    #print file_name[sen_type]\n",
    "    rule = open(file_name[sen_type])                        #open the respective file\n",
    "    for line in rule:                                       #reorder according to the rule\n",
    "        line = line.strip()\n",
    "        #print line\n",
    "        key, order = line.split('#')\n",
    "        key, order = key.strip(), order.strip()\n",
    "        tag_sen = re.sub(key, order, tag_sen)\n",
    "        #print tag_sen\n",
    "    \n",
    "    #print tag_sen\n",
    "    tag_sen = re.findall(r'\\(\\S+ \\S+?\\)', tag_sen)           #extract all the tags\n",
    "    #print tag_sen\n",
    "    tmp_str = ''\n",
    "    for item in tag_sen:\n",
    "        tmp_str += item + ','\n",
    "    tag_sen = tmp_str[: -1]\n",
    "    tag_sen = tag_sen.replace(' ', '\", \"')\n",
    "    tag_sen = tag_sen.replace('(', '(\"')\n",
    "    tag_sen = tag_sen.replace(')', '\")')\n",
    "    tag_sen = list(ast.literal_eval(tag_sen))\n",
    "    #print tag_sen\n",
    "    return tag_sen\n",
    "    \n",
    "#print reorder('What were you doing yesterday')\n",
    "#print reorder('When are you going to school')\n",
    "print reorder('They have eaten')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
